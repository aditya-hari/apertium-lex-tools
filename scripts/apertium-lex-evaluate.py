#!/usr/bin/python
# coding=utf-8
# -*- encoding: utf-8 -*-

import sys;

# src = output of translator up to lt-proc -b
# ref = reference corpus
# tst = output of lexical selection module

if len(sys.argv) < 4: #{
	print 'apertium-lex-evaluate <src> <ref> <tst>';
	sys.exit(-1);
#}

f_src = file(sys.argv[1]);
f_ref = file(sys.argv[2]);
f_tst = file(sys.argv[3]);

def lineToArray(line): #{
	current_word_sl = '';
	current_word_tl = '';
	current_words_tl = [];
	firstWord = False;
	inWord = False;
	lus = [];

	for c in line.decode('utf-8'): #{
		if c == '^': #{
			inWord = True;		
			firstWord = True;		
			continue;
		elif c == '$': #{
			current_words_tl.append(current_word_tl);
			current_word = (current_word_sl, current_words_tl);
			lus.append(current_word);	
			print current_word;
			current_word_sl = ''; 
			current_word_tl = ''; 
			current_words_tl = []; 
			i = 0;
			inWord = False;
			continue;
		elif c == '/': #{
			if not firstWord: #{
				current_words_tl.append(current_word_tl);
				current_word_tl = '';
			elif firstWord: #{
				firstWord = False;
			#}
			continue;
		#}

		if inWord and firstWord: #{
			current_word_sl = current_word_sl + c;
		elif inWord and not firstWord: 
			current_word_tl = current_word_tl + c;	
		#}
	#}
	return lus;
#}

def sanityChecks(l_src, l_ref, l_tst): #{
	print >> sys.stderr, '---';
	src_lu = []; 
	ref_lu = [];
	tst_lu = [];

	src_lu = lineToArray(l_src);
	ref_lu = lineToArray(l_ref);
	tst_lu = lineToArray(l_ref);

	if len(src_lu) != len(ref_lu): #{
		print >> sys.stderr, 'WARNING: Source and reference sentence have different number of lexical units.'
		print >> sys.stderr, len(src_lu) , ": " + l_src;
		print >> sys.stderr, len(ref_lu) , ": " + l_ref;
	#}

	if len(src_lu) != len(tst_lu): #{
		print >> sys.stderr, 'WARNING: Source and test sentence have different number of lexical units.'
		print >> sys.stderr, len(src_lu) , ": " + l_src;
		print >> sys.stderr, len(tst_lu) , ": " + l_tst;
	#}

#       i) do a sanity check, look for outN in tst that aren't in src: LEX module is outputting strange stuff

	for i in range(0, len(tst_lu)): #{
		if len(tst_lu[i][1]) > 1: #{
			print >> sys.stderr, 'WARNING: Test sentence has a translation with more than one option.';
			print >> sys.stderr, tst_lu[i][1];
		#}	
		for lu in tst_lu[i][1]: #{
			if lu not in src_lu[i][1]: #{
				print >> sys.stderr, 'WARNING: Test sentence has a translation option that can never be '
				print >> sys.stderr, ' generated by the MT system.'
				print >> sys.stderr, 'TST: ', tst_lu[i];
				print >> sys.stderr, 'SRC: ', src_lu[i];
			#}
		#}
	#}

#      ii) look for outN in ref that aren't in src: MT system has changed

	for i in range(0, len(ref_lu)): #{
		for lu in ref_lu[i][1]: #{
			if lu not in src_lu[i][1]: #{
				print >> sys.stderr, 'WARNING: Reference sentence has a translation option that can never be '
				print >> sys.stderr, ' generated by the MT system.'
				print >> sys.stderr, 'REF: ', ref_lu[i];
				print >> sys.stderr, 'SRC: ', src_lu[i];
			#}
		#}
	#}
#}

# Process:
#  Read linestep, for each line in the three files:
#    1) read into arrays src[0] = (in, [out1, out2]) , etc.
#    2) 
#       i) do a sanity check, look for outN in tst that aren't in src: LEX module is outputting strange stuff
#      ii) look for outN in ref that aren't in src: MT system has changed
#     iii) look for unambiguous words in src that have a different TL translation than in ref.
#    3) 
#       i) for each of the lines, 
#      ii)    for each of LUs, 
#     iii)        for each of the TL possibilities: check to see if it is in the ref
#      iv)            if it is in the ref, increase score for that LU by 1.
#       v)        final score is number of good TL translations / total number of TL translations

lines = True;

while lines: #{

	l_src = f_src.readline();		
	l_ref = f_ref.readline();		
	l_tst = f_tst.readline();		

	if l_src == '' and l_ref == '' and l_tst == '': #{
		lines = False;
	#}

	sanityChecks(l_src, l_ref, l_tst);
#}
